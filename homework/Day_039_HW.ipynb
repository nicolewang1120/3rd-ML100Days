{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [作業重點]\n",
    "清楚了解 L1, L2 的意義與差異為何，並了解 LASSO 與 Ridge 之間的差異與使用情境"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作業"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "請閱讀相關文獻，並回答下列問題\n",
    "\n",
    "[脊回歸 (Ridge Regression)](https://blog.csdn.net/daunxx/article/details/51578787)\n",
    "[Linear, Ridge, Lasso Regression 本質區別](https://www.zhihu.com/question/38121173)\n",
    "\n",
    "1. LASSO 回歸可以被用來作為 Feature selection 的工具，請了解 LASSO 模型為什麼可用來作 Feature selection\n",
    "2. 當自變數 (X) 存在高度共線性時，Ridge Regression 可以處理這樣的問題嗎?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1. 因為LASSO 回歸可以透過惩罚力度alpha來控制w的数值，而w數值越小就表示變數影響力越小，可以考慮從Feature selection中剔除。\n",
    "\n",
    "2. 可以，\n",
    "当设计矩阵X存在多重共线性的时候（数学上称为病态矩阵），最小二乘法求得的参数w在数值上会非常的大，\n",
    "因为w在数值上非常的大，所以，如果输入变量x有一个微小的变动，其反应在输出结果上也会变得非常大，这就是对输入变量总的噪声非常敏感的原因。\n",
    "为了限制模型参数w的数值大小，就在模型原来的目标函数上加上一个惩罚项，这个过程叫做正则化（Regularization）。\n",
    "正则化同时也是防止过拟合有效的手段。\n",
    "α的数值越大，那么正则项，也是惩罚项的作用就越明显\n",
    "alpha越大，则w的数值上越小\n",
    "\n",
    "既然惩罚力度alpha太大了容易拟合不足，太低了容易过度拟合。究竟多大的惩罚力度是合适的？"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
